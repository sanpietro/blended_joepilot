{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = Path(\"YOUR_TEXT\").read_text()\n",
    "print(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_length=1024):\n",
    "    chunks = []\n",
    "    words = text.split()\n",
    "    current_chunk = \"\"\n",
    "    for word in words:\n",
    "        if len(current_chunk) + len(word) < max_length:\n",
    "            current_chunk += f\" {word}\"\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = f\"{word}\"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text):\n",
    "    input_chunks = split_text(text)\n",
    "    output_chunks = []\n",
    "    for chunk in input_chunks:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"YOUR_DEPLOYMENT\",\n",
    "            messages =[ \n",
    "                {\"role\": \"system\", \"content\": \"This text is a chunked summary of a transcript. Create a coherent summary based on the text. Avoid repeating names and do not mention when participants join or leave the meeting\"},\n",
    "                {\"role\": \"user\", \"content\": chunk}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=1024,\n",
    "        )\n",
    "        summary = response['choices'][0]['message']['content']\n",
    "        output_chunks.append(summary)\n",
    "\n",
    "    concat_text= \" \".join(output_chunks)\n",
    "    print(concat_text)\n",
    "    return concat_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_of_summaries(summary_text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"YOUR_DEPLOYMENT\",\n",
    "        messages =[ \n",
    "            {\"role\": \"system\", \"content\": \"This is a transcript from a class on Power BI. Extract and list the key points from the provided text. Group the key points by topic and display each topic group first with the topic in bold and then the summary of the topic below. Avoid repeating names and do not mention when participants join or leave the meeting\"},\n",
    "            {\"role\": \"user\", \"content\": summary_text}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1500,\n",
    "        \n",
    "    )\n",
    "    summary_of_summary = response['choices'][0]['message']['content']\n",
    "    return summary_of_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = summary_of_summaries(source_text)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
